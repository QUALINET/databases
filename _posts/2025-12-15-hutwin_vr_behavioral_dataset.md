---
title: HuTwin Dataset - Multimodal Behavioral Dynamics in Collaborative VR Interactions
database: HuTwin VR Dataset
categories:
- video
author: Gulnaziye Bingol, Alessandro Floris, Luigi Atzori (University of Cagliari)
external_link: https://zenodo.org/records/17563391
access: Openly available for download from Zenodo
publicly_available: true
doi: 10.5281/zenodo.17563391
citation: 'Bingol, G., Floris, A., & Atzori, L. (2025). HuTwin Dataset [Dataset]. Zenodo. https://doi.org/10.5281/zenodo.17563391'
license: Creative Commons Attribution 4.0 International
subjective_scores: true
total: 120
tags:
- quality of experience
- virtual reality
- subjective quality assessment
- avatar
- facial expression
- speech emotion
- body movement
- multimodal
- collaborative vr
---

This comprehensive multimodal dataset captures behavioral dynamics during collaborative virtual reality interactions. The dataset includes synchronized recordings from 40 participants (20 pairs) performing a VR cooking-game task across three sessions, totaling 120 recordings.

The dataset encompasses objective behavioral measurements including body motion capture, facial expression tracking, and speech acoustic features, alongside subjective assessments of quality of experience, presence, and emotional responses. The experimental design uses a within-subjects approach manipulating multiple factors: avatar type (Chef vs. Humanoid), connection type (Host vs. Client), role (Student vs. Teacher), and network quality conditions (delay/jitter: 0ms vs. 500ms).

This research was conducted at the Net4U Laboratory, University of Cagliari, and funded by the European Commission through Next Generation EU and the Italian National Recovery Plan RESTART program. The dataset enables research on understanding how avatar design, network conditions, and social roles affect user experience, behavior, and emotions in collaborative VR environments. Related work by the research team was presented at QoMEX 2025 on QoE in multi-user collaborative VR games.
