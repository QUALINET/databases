---
access: 'Data and code available in archives:  Link: http://mclab.citi.sinica.edu.tw/dataset/lared/lared.html'
author: National Taiwan University
categories:
- image
citation: Use of the datasets in published work should be acknowledged by a full citation
  to the authors' papers [HSL14] at the MMSys conference (Proceedings of ACM MMSys
  2014, March 19 - March 21, 2014, Singapore, Singapore).
contact_name: Jordi Sanchez-Riera (jsan3386@citi.sinica.edu.tw)
database: 'LaRED: A Large RGB-D Extensible Hand Gesture Dataset'
broken_link: false
excerpt: ''
external_link: http://mclab.citi.sinica.edu.tw/dataset/lared/lared.html
other: Depth image
publicly_available: true
references:
  HSL14: 'Yuan-Sheng Hsiao, Jordi Sanchez-Riera, Tekoing Lim, Kai-Lung Hua, Wen-Huang
    Cheng, LaRED: a large RGB-D extensible hand gesture dataset, Proceedings of ACM
    MMSys 2014, March 19 - March 21, 2014, Singapore, Singapore.'
src: 27
subjective_scores: false
tags:
- image
title: 'LaRED: A Large RGB-D Extensible Hand Gesture Dataset'
total: 243000
---

The LaRED is recorded with the Intel's short range depth camera (the model number: VF0780-SDK-CE). In particular, the LaRED dataset contains 27 gestures in 3 different orientations, which makes a total of 81 classes. We have 10 subjects performing the corresponding hand gesture and 300 images are collected from each subject with the Intel camera providing a pair of synchornized color and depth images. Meanwhile, a mask image is given to localize the boundary of the gesture-performing hand.